{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### بسم الله الرحمن الرحيم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fcbb134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f3567c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641a1a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reade Data Set\n",
    "\n",
    "data_frame = pd.read_csv('./Data_Set/data_spam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813207ab",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595e471",
   "metadata": {},
   "source": [
    "#### get info of Data-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e257efbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display (rows, colmuns)\n",
    "\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a473604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 38 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   v1           5572 non-null   object\n",
      " 1   v2           5571 non-null   object\n",
      " 2   Unnamed: 2   255 non-null    object\n",
      " 3   Unnamed: 3   167 non-null    object\n",
      " 4   Unnamed: 4   32 non-null     object\n",
      " 5   Unnamed: 5   23 non-null     object\n",
      " 6   Unnamed: 6   10 non-null     object\n",
      " 7   Unnamed: 7   10 non-null     object\n",
      " 8   Unnamed: 8   5 non-null      object\n",
      " 9   Unnamed: 9   4 non-null      object\n",
      " 10  Unnamed: 10  4 non-null      object\n",
      " 11  Unnamed: 11  1 non-null      object\n",
      " 12  Unnamed: 12  1 non-null      object\n",
      " 13  Unnamed: 13  1 non-null      object\n",
      " 14  Unnamed: 14  1 non-null      object\n",
      " 15  Unnamed: 15  1 non-null      object\n",
      " 16  Unnamed: 16  1 non-null      object\n",
      " 17  Unnamed: 17  1 non-null      object\n",
      " 18  Unnamed: 18  1 non-null      object\n",
      " 19  Unnamed: 19  1 non-null      object\n",
      " 20  Unnamed: 20  1 non-null      object\n",
      " 21  Unnamed: 21  1 non-null      object\n",
      " 22  Unnamed: 22  1 non-null      object\n",
      " 23  Unnamed: 23  1 non-null      object\n",
      " 24  Unnamed: 24  1 non-null      object\n",
      " 25  Unnamed: 25  1 non-null      object\n",
      " 26  Unnamed: 26  1 non-null      object\n",
      " 27  Unnamed: 27  1 non-null      object\n",
      " 28  Unnamed: 28  1 non-null      object\n",
      " 29  Unnamed: 29  1 non-null      object\n",
      " 30  Unnamed: 30  1 non-null      object\n",
      " 31  Unnamed: 31  1 non-null      object\n",
      " 32  Unnamed: 32  1 non-null      object\n",
      " 33  Unnamed: 33  1 non-null      object\n",
      " 34  Unnamed: 34  1 non-null      object\n",
      " 35  Unnamed: 35  1 non-null      object\n",
      " 36  Unnamed: 36  1 non-null      object\n",
      " 37  Unnamed: 37  1 non-null      object\n",
      "dtypes: object(38)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# show information about dataset\n",
    "\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c1f5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change columns name\n",
    "data_frame.rename(columns={'v1': 'label', 'v2':'text'}, inplace=True)\n",
    "data_frame = data_frame[['label', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424ade9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5572\n",
       "unique       2\n",
       "top        ham\n",
       "freq      4825\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show description information of data_frame['label']\n",
    "\n",
    "data_frame['label'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df082fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       5571\n",
       "unique                      5163\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show description information of data_frame['text']\n",
    "\n",
    "data_frame['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480e2c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b35345d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of missing values in the dataset\n",
    "\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "702b79e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of duplicated values in the data_frame\n",
    "\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6067a8",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90ba965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing the null values with empty string\n",
    "\n",
    "data_frame = data_frame.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a856373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove duplicated values in the data_frame\n",
    "\n",
    "data_frame = data_frame.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6592f931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace \"spam\" with 0 & \"ham\" with 1\n",
    "\n",
    "data_frame['label'].replace({'spam': 0, 'ham': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b31f32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Go until jurong point, crazy.. Available only ...\n",
       "1      1                      Ok lar... Joking wif u oni...\n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      1  U dun say so early hor... U c already then say...\n",
       "4      1  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23a12474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function take text then return the same text without punctuation.\n",
    "\n",
    "def remove_punctuations(content):\n",
    "    content = content.lower()\n",
    "    return content.translate(str.maketrans(\"\",\"\",string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bb846a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply above function on data_frame['text']\n",
    "# recive new text in new column named unpunctuated_text\n",
    "\n",
    "data_frame['unpunctuated_text'] = data_frame['text'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa76e763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing new column [unpunctuated_text]\n",
    "\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60e1ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    " apply tokenization on data_frame['unpunctuated_text'] to split text into list of words then return this list\n",
    " recive list_of_words in new column named tokenized_words\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data_frame['tokenized_words'] = data_frame['unpunctuated_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2ca698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing new column [tokenized_words]\n",
    "\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884dfe4e",
   "metadata": {},
   "source": [
    "#### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5112e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'doing', 'd', 'for', 'be', 'll', 'its', 'about', 't', 'your', 'both', \"doesn't\", 'ours', 'just', \"shan't\", \"mustn't\", 'yourselves', 'how', 'there', 'all', 'itself', 'being', 'does', \"aren't\", 'these', 'each', 'against', 'can', 'am', 'so', 'same', \"wouldn't\", \"shouldn't\", 'doesn', 'myself', 'her', 'and', 'from', 'more', 'herself', 'have', 'over', 'their', 'off', 'me', \"you'll\", 'them', 'been', 'isn', 'our', 'if', 'now', 'that', 'is', 'a', 'hasn', 'when', 'had', 'did', 's', \"don't\", 'other', 'above', 'under', 'while', 'during', 'up', 'because', 'theirs', 'this', 'few', 'o', \"weren't\", 'haven', 'but', 'which', \"needn't\", 'themselves', \"it's\", 'any', 'will', \"hasn't\", 'than', 'where', 'his', 'aren', 'once', 'out', 'hadn', 'they', 'were', 'or', 'y', 'he', 'no', 'shouldn', 'yourself', 'those', 'an', \"couldn't\", 'was', 'are', 'until', 'then', 'into', 'should', \"you're\", 'm', \"won't\", 'nor', 'very', 'down', 'with', 'yours', 'in', \"haven't\", 'again', 'after', \"should've\", 'why', 'has', \"you've\", 'i', \"you'd\", 'himself', 'through', 'below', 'on', 'not', 'some', 'him', 'shan', 'hers', 'by', 'as', 'didn', 'won', \"mightn't\", 'to', 'mustn', 'such', 'my', 'she', 'we', 'needn', 'what', 'the', \"hadn't\", 'too', 'couldn', \"she's\", 'here', 'own', 'ain', 'whom', 'having', 'do', 'weren', 'most', \"wasn't\", 'it', 'you', 'ma', 'ourselves', 'at', 'don', 'wouldn', 'further', \"that'll\", 'only', 've', \"isn't\", 'who', 're', 'before', \"didn't\", 'between', 'wasn', 'mightn'}\n"
     ]
    }
   ],
   "source": [
    "# get stop words in english to remove from my text\n",
    "\n",
    "stopwords_list = set(stopwords.words('english')) \n",
    "\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e416ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(content):\n",
    "    content = [word for word in content if not word in stopwords_list]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f963a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply remove_stopwords function to remove from tokenized_words _list\n",
    "\n",
    "data_frame['tokenized_words'] = data_frame['tokenized_words'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9538e",
   "metadata": {},
   "source": [
    " #### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c184ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25e57d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " function for stemming take tokenizd_words_list then make stem for very word in tokenizd_words_list\n",
    " return Text (not List) after stemming\n",
    "\"\"\"\n",
    "\n",
    "def stemming(content):\n",
    "    stemmed_content = [port_stem.stem(word) for word in content]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c93956d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply stemming function on tokenized words\n",
    "\n",
    "data_frame['stemmed_text'] = data_frame['tokenized_words'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea20010d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4          nah dont think goe usf live around though  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d6e71",
   "metadata": {},
   "source": [
    "#### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "976a1e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efe9e650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " function for lemetize text take tokenizd_words_list then make stem for very word in tokenizd_words_list\n",
    " return Text (not List) after lemetizing\n",
    "\"\"\"\n",
    "\n",
    "def lemetize(content):\n",
    "    lemetized_content = [lemmatizer.lemmatize(word) for word in content]\n",
    "    lemetized_content = ' '.join(lemetized_content)\n",
    "    return lemetized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd41dab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excute lemtization function on data\n",
    "\n",
    "data_frame['lemetized_text'] = data_frame['tokenized_words'].apply(lemetize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e54165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemetized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  go jurong point crazi avail bugi n great world...   \n",
       "1                              ok lar joke wif u oni   \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...   \n",
       "3                u dun say earli hor u c alreadi say   \n",
       "4          nah dont think goe usf live around though   \n",
       "\n",
       "                                      lemetized_text  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4           nah dont think go usf life around though  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5b400",
   "metadata": {},
   "source": [
    "#### divide data into X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe14eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put text in X\n",
    "\n",
    "X = data_frame['lemetized_text'].values # input data\n",
    "\n",
    "# put label value to Y\n",
    "\n",
    "Y = data_frame['label'].values # result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a8292",
   "metadata": {},
   "source": [
    "#### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8234c60f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer(stop_words='english')\n",
    "\n",
    "bow.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c29686de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['008704050406' '0089my' '0121' ... 'zoom' 'zouk' 'zyada']\n"
     ]
    }
   ],
   "source": [
    "# show Extraction Feature \n",
    "\n",
    "print(bow.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18f71a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform X to numerical data\n",
    "\n",
    "X = bow.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3884a8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1125)\t1\n",
      "  (0, 1331)\t1\n",
      "  (0, 1746)\t1\n",
      "  (0, 1748)\t1\n",
      "  (0, 2050)\t1\n",
      "  (0, 2308)\t1\n",
      "  (0, 3498)\t1\n",
      "  (0, 3535)\t1\n",
      "  (0, 4250)\t1\n",
      "  (0, 4392)\t1\n",
      "  (0, 5780)\t1\n",
      "  (0, 8016)\t1\n",
      "  (0, 8222)\t1\n",
      "  (1, 4220)\t1\n",
      "  (1, 4424)\t1\n",
      "  (1, 5394)\t1\n",
      "  (1, 5421)\t1\n",
      "  (1, 8129)\t1\n",
      "  (2, 71)\t1\n",
      "  (2, 436)\t1\n",
      "  (2, 449)\t1\n",
      "  (2, 850)\t1\n",
      "  (2, 1199)\t1\n",
      "  (2, 2157)\t1\n",
      "  (2, 2359)\t1\n",
      "  :\t:\n",
      "  (5159, 5296)\t1\n",
      "  (5159, 5841)\t1\n",
      "  (5159, 5933)\t1\n",
      "  (5159, 7481)\t1\n",
      "  (5159, 7634)\t1\n",
      "  (5160, 2924)\t1\n",
      "  (5160, 3249)\t1\n",
      "  (5160, 3463)\t1\n",
      "  (5160, 3804)\t1\n",
      "  (5161, 5015)\t1\n",
      "  (5161, 5710)\t1\n",
      "  (5161, 6825)\t1\n",
      "  (5161, 7155)\t1\n",
      "  (5162, 967)\t1\n",
      "  (5162, 1553)\t1\n",
      "  (5162, 1780)\t1\n",
      "  (5162, 3260)\t1\n",
      "  (5162, 3367)\t1\n",
      "  (5162, 3588)\t1\n",
      "  (5162, 3939)\t1\n",
      "  (5162, 4063)\t1\n",
      "  (5162, 4521)\t1\n",
      "  (5162, 8060)\t1\n",
      "  (5163, 6336)\t1\n",
      "  (5163, 7645)\t1\n"
     ]
    }
   ],
   "source": [
    "# show X after apply Bag of Words\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53cd8720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0ce57",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2eee025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spliting the dataset to (80%) training data & (20%) test data\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a63dc",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "909e364c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c0087a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b36c68ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# accuracy score on the training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "precision = accuracy_score(X_train_prediction, Y_train)\n",
    "recall = recall_score(X_train_prediction, Y_train)\n",
    "f1score = f1_score(X_train_prediction, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a601bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data :  0.9937061244250787\n",
      "Recall :  0.992847317744154\n",
      "f1socre :  0.996410822749862\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the training data : ', precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1socre : \",f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1cd913d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# accuracy score on the test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "precision = accuracy_score(X_test_prediction, Y_test)\n",
    "recall = recall_score(X_test_prediction, Y_test)\n",
    "f1score = f1_score(X_test_prediction, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9faee48e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.9757986447241046\n",
      "Recall :  0.9750812567713976\n",
      "f1socre :  0.9863013698630138\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the test data : ', precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1socre : \",f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97cb52",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c073fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a933cc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a161967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71e60280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accuracy score on the training data\n",
    "X_train_prediction = svm.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abe6306f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data :  0.9946744129750665\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ea56799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accuracy score on the test data\n",
    "X_test_prediction = svm.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d807dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.9661181026137464\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e835bf58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.9636363636363636\n",
      "Recall :  0.9988913525498891\n",
      "f1socre :  0.9809471965160589\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(Y_test, X_test_prediction)\n",
    "recall = recall_score(Y_test, X_test_prediction)\n",
    "f1score = f1_score(Y_test, X_test_prediction)\n",
    "print(\"Precision : \",precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1socre : \",f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9f11e",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a605986a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50c821b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7db33014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accuracy score on the training data\n",
    "X_train_prediction = clf.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42a8b7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08b3432f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accuracy score on the test data\n",
    "X_test_prediction = clf.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7930da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.957405614714424\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7148ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.9693654266958425\n",
      "Recall :  0.9822616407982262\n",
      "f1socre :  0.9757709251101322\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(Y_test, X_test_prediction)\n",
    "recall = recall_score(Y_test, X_test_prediction)\n",
    "f1score = f1_score(Y_test, X_test_prediction)\n",
    "print(\"Precision : \",precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1socre : \",f1score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
