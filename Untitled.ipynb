{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06776bba",
   "metadata": {},
   "source": [
    "### بسم الله الرحمن الرحيم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "00d2718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f279f39",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e6615943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f29e2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "eb00c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e453fd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"isn't\", 'than', 'should', 'him', 'ourselves', 'all', 'how', 'hers', 'if', 'were', 'that', 'am', 'doing', 'down', 'our', 's', 'didn', 'from', 'myself', 'very', 'my', 'once', 'again', 'as', \"weren't\", 'who', 'itself', 'it', 'a', \"hadn't\", 'yourself', 'are', \"haven't\", 'its', 'same', 'through', 'mightn', 'ma', \"that'll\", 't', 'had', 'couldn', 'between', 'few', 'about', 'while', 'too', 'you', 'have', 'not', 'can', 'which', 'y', 'was', 'these', 'above', 'up', 'me', 'nor', 'theirs', 'i', 'hasn', 'herself', 'with', 'the', 'her', 'don', 'm', \"mightn't\", 'weren', 'further', \"doesn't\", 'off', \"should've\", 'themselves', 'of', 'such', 'what', \"needn't\", 'their', 'will', \"aren't\", \"don't\", 've', 'this', 'needn', 'after', 'his', 'those', 'he', 'more', 'now', 're', 'to', 'most', \"you'd\", 'into', 'has', \"couldn't\", 'then', 'shan', 'ours', 'there', \"you're\", 'but', 'when', 'own', 'here', 'so', 'they', 'won', 'wasn', \"didn't\", 'on', 'during', 'before', 'ain', 'himself', \"you'll\", 'she', \"it's\", 'them', 'doesn', 'o', 'haven', 'being', 'll', 'out', 'yours', \"hasn't\", 'does', 'wouldn', 'and', 'against', 'did', 'only', 'hadn', 'your', 'aren', 'having', 'until', 'been', 'under', 'for', 'each', 'by', 'other', 'why', \"you've\", 'd', \"shan't\", 'over', 'some', 'whom', 'or', 'below', 'be', 'no', 'isn', \"won't\", 'just', 'at', 'yourselves', 'any', 'mustn', \"mustn't\", 'shouldn', 'both', 'we', 'an', \"shouldn't\", 'where', 'because', \"she's\", 'in', 'do', \"wouldn't\", \"wasn't\", 'is'}\n"
     ]
    }
   ],
   "source": [
    "stopwords_list = set(stopwords.words('english'))\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "942d00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('./Data_Set/data_spam.csv')\n",
    "# pd.set_option('display.max_rows', data_frame.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "084a7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns name\n",
    "data_frame.rename(columns={'v1': 'label', 'v2':'text'}, inplace=True)\n",
    "data_frame = data_frame[['label', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4accb746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   text    5571 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# show insformation about dataset\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1f2d74cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                    text\n",
       "count   5572                    5571\n",
       "unique     2                    5163\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display description of data Frame\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "65bcb9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       5571\n",
       "unique                      5163\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display description of text column\n",
    "data_frame['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "11437247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display (rows, colmuns)\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d4ef5627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 5 rows\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "45ffd1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of missing values in the dataset\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "88d025ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the null values with empty string\n",
    "data_frame = data_frame.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "821b60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of duplicated values in the data_frame\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d49774a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated values in the data_frame\n",
    "data_frame = data_frame.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "54fbff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"spam\" with 0 & \"ham\" with 1\n",
    "data_frame['label'].replace({'spam': 0, 'ham': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "eaedf738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Go until jurong point, crazy.. Available only ...\n",
       "1      1                      Ok lar... Joking wif u oni...\n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      1  U dun say so early hor... U c already then say...\n",
       "4      1  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ec5f8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_punctuations(content):\n",
    "    content = content.lower()\n",
    "    return content.translate(str.maketrans(\"\",\"\",string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "af1797bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['unpunctuated_text'] = data_frame['text'].apply(removing_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "433d6016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "20faac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "91b5eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords_list]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4d0caf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['stemmed_text'] = data_frame['unpunctuated_text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1095c16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4          nah dont think goe usf live around though  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0556229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemetization function\n",
    "def lemetize(content):\n",
    "    lemetized_content = content.split()\n",
    "    lemetized_content = [lemmatizer.lemmatize(word) for word in lemetized_content]\n",
    "    lemetized_content = ' '.join(lemetized_content)\n",
    "    return lemetized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "27d7f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excute lemtization function on data\n",
    "data_frame['lemetized_text'] = data_frame['unpunctuated_text'].apply(lemetize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e6b87d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemetized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "      <td>nah i dont think he go to usf he life around h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                   unpunctuated_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  go jurong point crazi avail bugi n great world...   \n",
       "1                              ok lar joke wif u oni   \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...   \n",
       "3                u dun say earli hor u c alreadi say   \n",
       "4          nah dont think goe usf live around though   \n",
       "\n",
       "                                      lemetized_text  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he go to usf he life around h...  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2ebe0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applay tokenization function\n",
    "data_frame['tokenized_words'] = data_frame['lemetized_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c6acaa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unpunctuated_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemetized_text</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "      <td>nah i dont think he go to usf he life around h...</td>\n",
       "      <td>[nah, i, dont, think, he, go, to, usf, he, lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey there darling its been 3 weeks now...</td>\n",
       "      <td>freemsg hey darl 3 week word back id like fun ...</td>\n",
       "      <td>freemsg hey there darling it been 3 week now a...</td>\n",
       "      <td>[freemsg, hey, there, darling, it, been, 3, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "      <td>per request mell mell oru minnaminungint nurun...</td>\n",
       "      <td>a per your request melle melle oru minnaminung...</td>\n",
       "      <td>[a, per, your, request, melle, melle, oru, min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "      <td>winner valu network custom select receivea �90...</td>\n",
       "      <td>winner a a valued network customer you have be...</td>\n",
       "      <td>[winner, a, a, valued, network, customer, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>had your mobile 11 months or more u r entitled...</td>\n",
       "      <td>mobil 11 month u r entitl updat latest colour ...</td>\n",
       "      <td>had your mobile 11 month or more u r entitled ...</td>\n",
       "      <td>[had, your, mobile, 11, month, or, more, u, r,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  Go until jurong point, crazy.. Available only ...   \n",
       "1      1                      Ok lar... Joking wif u oni...   \n",
       "2      0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      1  U dun say so early hor... U c already then say...   \n",
       "4      1  Nah I don't think he goes to usf, he lives aro...   \n",
       "5      0  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6      1  Even my brother is not like to speak with me. ...   \n",
       "7      1  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8      0  WINNER!! As a valued network customer you have...   \n",
       "9      0  Had your mobile 11 months or more? U R entitle...   \n",
       "\n",
       "                                   unpunctuated_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "5  freemsg hey there darling its been 3 weeks now...   \n",
       "6  even my brother is not like to speak with me t...   \n",
       "7  as per your request melle melle oru minnaminun...   \n",
       "8  winner as a valued network customer you have b...   \n",
       "9  had your mobile 11 months or more u r entitled...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  go jurong point crazi avail bugi n great world...   \n",
       "1                              ok lar joke wif u oni   \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...   \n",
       "3                u dun say earli hor u c alreadi say   \n",
       "4          nah dont think goe usf live around though   \n",
       "5  freemsg hey darl 3 week word back id like fun ...   \n",
       "6      even brother like speak treat like aid patent   \n",
       "7  per request mell mell oru minnaminungint nurun...   \n",
       "8  winner valu network custom select receivea �90...   \n",
       "9  mobil 11 month u r entitl updat latest colour ...   \n",
       "\n",
       "                                      lemetized_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he go to usf he life around h...   \n",
       "5  freemsg hey there darling it been 3 week now a...   \n",
       "6  even my brother is not like to speak with me t...   \n",
       "7  a per your request melle melle oru minnaminung...   \n",
       "8  winner a a valued network customer you have be...   \n",
       "9  had your mobile 11 month or more u r entitled ...   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, go, to, usf, he, lif...  \n",
       "5  [freemsg, hey, there, darling, it, been, 3, we...  \n",
       "6  [even, my, brother, is, not, like, to, speak, ...  \n",
       "7  [a, per, your, request, melle, melle, oru, min...  \n",
       "8  [winner, a, a, valued, network, customer, you,...  \n",
       "9  [had, your, mobile, 11, month, or, more, u, r,...  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "cda82598",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame['lemetized_text'].values # input data\n",
    "Y = data_frame['label'].values # result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "db6bc5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'\n",
      " 'ok lar joking wif u oni'\n",
      " 'free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s'\n",
      " ... 'pity wa in mood for that soany other suggestion'\n",
      " 'the guy did some bitching but i acted like id be interested in buying something else next week and he gave it to u for free'\n",
      " 'rofl it true to it name']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "471f0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the textual data to numerical data\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e292ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8491)\t0.2309218750279521\n",
      "  (0, 8263)\t0.18687785983494606\n",
      "  (0, 8021)\t0.2309218750279521\n",
      "  (0, 7632)\t0.15791531910805345\n",
      "  (0, 5964)\t0.22351212751204189\n",
      "  (0, 5597)\t0.160260545944459\n",
      "  (0, 4527)\t0.27583716379007334\n",
      "  (0, 4383)\t0.3270259593188449\n",
      "  (0, 4115)\t0.10983626863124553\n",
      "  (0, 3642)\t0.18408220757620894\n",
      "  (0, 3604)\t0.15362936454639892\n",
      "  (0, 3552)\t0.14535610284318143\n",
      "  (0, 2366)\t0.25262584515728814\n",
      "  (0, 2104)\t0.27583716379007334\n",
      "  (0, 1796)\t0.27583716379007334\n",
      "  (0, 1794)\t0.3120541963981378\n",
      "  (0, 1363)\t0.25262584515728814\n",
      "  (0, 1143)\t0.3270259593188449\n",
      "  (1, 8393)\t0.430072403170494\n",
      "  (1, 5591)\t0.5460452394462293\n",
      "  (1, 5561)\t0.2795386833865282\n",
      "  (1, 4559)\t0.4065704703661188\n",
      "  (1, 4353)\t0.5229062072934929\n",
      "  (2, 8446)\t0.18893457134886524\n",
      "  (2, 8407)\t0.14402125725756823\n",
      "  :\t:\n",
      "  (5162, 7041)\t0.1854374037896603\n",
      "  (5162, 5352)\t0.20965061537346655\n",
      "  (5162, 4658)\t0.1602873349093203\n",
      "  (5162, 4247)\t0.11554552633627473\n",
      "  (5162, 4191)\t0.2862026300577176\n",
      "  (5162, 4115)\t0.11396371876094434\n",
      "  (5162, 4061)\t0.2368617349186012\n",
      "  (5162, 3783)\t0.17339386261120446\n",
      "  (5162, 3695)\t0.2103055455557878\n",
      "  (5162, 3469)\t0.27400187699392164\n",
      "  (5162, 3358)\t0.1632645590268894\n",
      "  (5162, 3312)\t0.12235293336505848\n",
      "  (5162, 2923)\t0.242548073796827\n",
      "  (5162, 2638)\t0.18720326853683167\n",
      "  (5162, 1829)\t0.28169006954193926\n",
      "  (5162, 1822)\t0.13849066695822823\n",
      "  (5162, 1599)\t0.33931500878334453\n",
      "  (5162, 1495)\t0.14357763827406758\n",
      "  (5162, 1158)\t0.11280583583047243\n",
      "  (5162, 970)\t0.32378063384404854\n",
      "  (5163, 7880)\t0.4878646730718293\n",
      "  (5163, 7744)\t0.16201051568120436\n",
      "  (5163, 6523)\t0.5980545550430295\n",
      "  (5163, 5270)\t0.42755637706216754\n",
      "  (5163, 4247)\t0.4418901981295636\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3230bc2d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "abfdc3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the dataset to (80%) training data & (20%) test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fce4db26",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a7379fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "55d9ea89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9df8c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# accuracy score on the training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "dcf5531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data :  0.9670781893004116\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "19ee6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# accuracy score on the test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "0edfcb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.9603097773475314\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb4f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07f47a0c",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8435a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a4df466",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64dcf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dfaffcb",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422506e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
